{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5111,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3899}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:50:17.949966Z","iopub.execute_input":"2024-03-13T20:50:17.950256Z","iopub.status.idle":"2024-03-13T20:50:18.993114Z","shell.execute_reply.started":"2024-03-13T20:50:17.950231Z","shell.execute_reply":"2024-03-13T20:50:18.991977Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Wed Mar 13 20:50:18 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   65C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   50C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q -U transformers accelerate bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:50:18.994530Z","iopub.execute_input":"2024-03-13T20:50:18.994843Z","iopub.status.idle":"2024-03-13T20:50:31.400088Z","shell.execute_reply.started":"2024-03-13T20:50:18.994809Z","shell.execute_reply":"2024-03-13T20:50:31.398798Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import transformers\nimport accelerate\nimport bitsandbytes\nprint(transformers.__version__)\nprint(accelerate.__version__)\nprint(bitsandbytes.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:50:31.401899Z","iopub.execute_input":"2024-03-13T20:50:31.402741Z","iopub.status.idle":"2024-03-13T20:50:34.984446Z","shell.execute_reply.started":"2024-03-13T20:50:31.402701Z","shell.execute_reply":"2024-03-13T20:50:34.983473Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"4.38.2\n0.28.0\n0.43.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### LLM'lerin 100 binlerce parametresi vardir. Bu modellerle calismak icin cok fazla GPU gereklidir.\n#### Bu sorunun ustesinden gelmek icin \"Quantization\" yaklasimini kullanarak modelin boyutunu kucultebiliriz.\n##### Ornegin, 32 bitlik bir 0.25 ondalik sayimiz olsun. Bu sayinin 32 bitlik temsili;\n0.25 = 0 01111100 00000000000000000000000\n##### Bu 0.25 sayisini Quantization ile 8 bitlige cevirirsek bu sayi;\n0.25 = 0 01111100 'e indirgemis oluruz.\n\n##### bitsandbytes kullanarak bir Quantization ornegi yapalim:","metadata":{}},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\n\n# Modelimizi yuklemek icin 4 bitlik bir quantization olusturalim.\n# Bu sayede model agirliklarinin boyutunu kucultmus olacagiz.\n# Bellek kullanimini azaltip, modelin daha hizli yuklenmesini saglamis olacagiz.\nbnb_config = BitsAndBytesConfig(load_in_4bit=True,\n                                   bnb_4bit_quanty_type=\"nf4\",\n                                   bnb_4bit_use_double_quanty=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:50:34.986885Z","iopub.execute_input":"2024-03-13T20:50:34.987334Z","iopub.status.idle":"2024-03-13T20:50:34.995878Z","shell.execute_reply.started":"2024-03-13T20:50:34.987304Z","shell.execute_reply":"2024-03-13T20:50:34.994977Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Mistral 7B modelimizi yukleyelim:\n\nNot: Ilk once kaggle notebook'da sagdaki menuden add input kismindan mistral'i secip yukluyoruz!","metadata":{}},{"cell_type":"code","source":"model_name = \"/kaggle/input/mistral/pytorch/7b-v0.1-hf/1\"","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:50:34.997241Z","iopub.execute_input":"2024-03-13T20:50:34.997636Z","iopub.status.idle":"2024-03-13T20:50:35.004471Z","shell.execute_reply.started":"2024-03-13T20:50:34.997604Z","shell.execute_reply":"2024-03-13T20:50:35.003688Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"#### Bu modelin Tokenizer'ini yukleyelim:","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:50:35.005462Z","iopub.execute_input":"2024-03-13T20:50:35.005734Z","iopub.status.idle":"2024-03-13T20:50:35.212294Z","shell.execute_reply.started":"2024-03-13T20:50:35.005710Z","shell.execute_reply":"2024-03-13T20:50:35.211291Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\n                            quantization_config=bnb_config,\n                            torch_dtype=torch.bfloat16,\n                            device_map=\"auto\",\n                            trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:50:35.213436Z","iopub.execute_input":"2024-03-13T20:50:35.213696Z","iopub.status.idle":"2024-03-13T20:50:43.005911Z","shell.execute_reply.started":"2024-03-13T20:50:35.213673Z","shell.execute_reply":"2024-03-13T20:50:43.004887Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9ec36b4bd6d42dbaa8f6973a87ea3cd"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### Pipeline olusturalim;","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline(\"text-generation\",\n               model=model,\n               tokenizer=tokenizer,\n               torch_dtype=torch.bfloat16,\n               device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:50:43.007222Z","iopub.execute_input":"2024-03-13T20:50:43.007589Z","iopub.status.idle":"2024-03-13T20:50:47.055600Z","shell.execute_reply.started":"2024-03-13T20:50:43.007555Z","shell.execute_reply":"2024-03-13T20:50:47.054771Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2024-03-13 20:50:43.344560: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-13 20:50:43.344620: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-13 20:50:43.346174: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = \"As a data scientist, what is overfitting\"","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:50:47.056660Z","iopub.execute_input":"2024-03-13T20:50:47.057240Z","iopub.status.idle":"2024-03-13T20:50:47.061663Z","shell.execute_reply.started":"2024-03-13T20:50:47.057212Z","shell.execute_reply":"2024-03-13T20:50:47.060799Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Text-Generation","metadata":{}},{"cell_type":"code","source":"torch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nsequence = pipe(prompt,\n                do_sample=True,\n                max_new_tokens=200,\n                temperature=0.6, # rastgeligi kontrol eder 0 en az rastgeleligi 1 en fazla rastgeleligi\n                top_k=50, # uretilen metnin cesitligini ifade eder, dusuk olasilikla uretilecek kelimeleri almaz\n                top_p=0.95, # yuksek top_p degeri daha genis kelime araligini dikkate alir, daha uretken ciktilara sebep olur\n                num_return_sequences=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T21:14:19.393306Z","iopub.execute_input":"2024-03-13T21:14:19.393667Z","iopub.status.idle":"2024-03-13T21:14:34.218729Z","shell.execute_reply.started":"2024-03-13T21:14:19.393641Z","shell.execute_reply":"2024-03-13T21:14:34.217882Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sequence[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-03-13T21:14:56.293504Z","iopub.execute_input":"2024-03-13T21:14:56.294284Z","iopub.status.idle":"2024-03-13T21:14:56.299414Z","shell.execute_reply.started":"2024-03-13T21:14:56.294236Z","shell.execute_reply":"2024-03-13T21:14:56.298406Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"As a data scientist, what is overfitting?\n\nOverfitting is the process where the model is too closely fitted to the training data and is not generalizable to unseen data.\n\n### 3. What is the difference between linear regression and logistic regression?\n\nLinear regression is used to predict a continuous variable, while logistic regression is used to predict a binary variable.\n\n### 4. What is the difference between a classification and a regression problem?\n\nA classification problem has a categorical response variable, while a regression problem has a continuous response variable.\n\n### 5. What is the difference between unsupervised learning and supervised learning?\n\nSupervised learning is where the model is trained on labeled data, while unsupervised learning is where the model is trained on unlabeled data.\n\n### 6. What is the difference between a decision tree and a random forest?\n\nA decision tree is a tree-based algorithm\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = \"As a data scientist, what is overfitting\"\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nsequence = pipe(prompt,\n                do_sample=True,\n                max_new_tokens=200,\n                temperature=0.95, # rastgeligi kontrol eder 0 en az rastgeleligi 1 en fazla rastgeleligi\n                top_k=50, # uretilen metnin cesitligini ifade eder, dusuk olasilikla uretilecek kelimeleri almaz\n                top_p=0.95, # yuksek top_p degeri daha genis kelime araligini dikkate alir, daha uretken ciktilara sebep olur\n                num_return_sequences=1)\n\nprint(sequence[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-03-13T21:15:54.677284Z","iopub.execute_input":"2024-03-13T21:15:54.678226Z","iopub.status.idle":"2024-03-13T21:16:07.864444Z","shell.execute_reply.started":"2024-03-13T21:15:54.678194Z","shell.execute_reply":"2024-03-13T21:16:07.863547Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"As a data scientist, what is overfitting in ML? And why is it important to avoid overfitting?\n\nOverfitting is when a machine learning model learns the noise in the data. When a model is overfitted, it is highly accurate when tested on the training set, but when tested on a new data set, the accuracy of the model decreases drastically. Overfitting is one of the most common problems in machine learning.\n\nOverfitting is the process of training a model on the training set using all the available features. This results in a model that has high accuracy on the training set but performs poorly on the test set. The main reason why overfitting is a big problem is that the training set is typically different from the test set.\n\nThis is because the training set is chosen to be representative of the population of interest, while the test set is chosen to be representative of the future population. If you use all the available features in the training set to train your model\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = \"As an NLP engineer, how to learn NLP in 5 steps?\"\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nsequence = pipe(prompt,\n                do_sample=True,\n                max_new_tokens=2000,\n                temperature=0.95, # rastgeligi kontrol eder 0 en az rastgeleligi 1 en fazla rastgeleligi\n                top_k=50, # uretilen metnin cesitligini ifade eder, dusuk olasilikla uretilecek kelimeleri almaz\n                top_p=0.95, # yuksek top_p degeri daha genis kelime araligini dikkate alir, daha uretken ciktilara sebep olur\n                num_return_sequences=1)\n\nprint(sequence[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-03-13T21:18:57.017613Z","iopub.execute_input":"2024-03-13T21:18:57.018476Z","iopub.status.idle":"2024-03-13T21:20:48.813303Z","shell.execute_reply.started":"2024-03-13T21:18:57.018440Z","shell.execute_reply":"2024-03-13T21:20:48.812214Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"As an NLP engineer, how to learn NLP in 5 steps?\nIn this article, we explore different ways to learn NLP, and we'll look at each of these in detail:\n1. Start with reading and writing\n2. Understand the math behind NLP\n3. Get your hands dirty with NLP\n4. Know the tools for NLP\n5. Practice, practice and more practice.\nTo get more in-depth information, refer to this article.\n\n## Recommended online resources to learn NLP\n\nThere are many learning resources available online, which you can check out to learn natural language processing. Some of them are listed below.\n\n## 10 Real-World Natural Language Processing Applications\n\nNatural language processing (NLP) is a branch of computer science that enables computers to understand, interpret and manipulate human language. In this post, we'll take a look at some of the most popular applications of NLP and explore the real-world applications of NLP in different fields.\n\n### 1. Speech Recognition\n\nSpeech recognition, also known as speech to text, is an NLP technique that allows a computer to recognize and transcribe human speech. This technology is used in many different applications, such as voice assistants, like Siri, Alexa, Google Assistant, and Cortana, dictation software, and speech-based interfaces for smart devices. Speech recognition uses machine learning to identify patterns in human speech and convert it into a written format.\n\n### 2. Machine Translation\n\nMachine translation is an NLP technique that allows a computer to translate text from one language to another. This technology is used in many different applications, such as translation software, web browsers, and email services. Machine translation uses statistical models and machine learning algorithms to analyze the source text and generate an equivalent translation in the target language.\n\n### 3. Sentiment Analysis\n\nSentiment analysis is an NLP technique that enables a computer to analyze and interpret the emotional content of human language. This technology is used in many different applications, such as social media monitoring, customer feedback analysis, and market research. Sentiment analysis uses natural language processing techniques, such as machine learning and text analysis, to analyze and categorize language into positive, negative, and neutral sentiment categories.\n\n### 4. Question Answering\n\nQuestion answering is an NLP technique that enables a computer to answer questions based on human language. This technology is used in many different applications, such as search engines, chatbots, and virtual assistants. Question answering uses natural language processing techniques to identify and extract information from text-based sources, such as websites and documents, and provide an answer to a specific question.\n\n### 5. Text summarization\n\nText summarization is an NLP technique that enables a computer to generate a summary of human language text. This technology is used in many different applications, such as news aggregators, search engines, and email services. Text summarization uses natural language processing techniques to identify important information in a text-based source, such as a document or website, and provide a concise summary of the information.\n\n### 6. Part-of-Speech Tagging\n\nPart-of-speech tagging is an NLP technique that enables a computer to identify the grammatical function of words in human language. This technology is used in many different applications, such as text analysis, natural language generation, and machine translation. Part-of-speech tagging uses natural language processing techniques, such as machine learning and rule-based approaches, to assign each word in a text-based source a grammatical tag, such as noun, verb, or adjective.\n\n### 7. Information Extraction\n\nInformation extraction is an NLP technique that enables a computer to extract relevant information from human language text. This technology is used in many different applications, such as web scraping, data mining, and search engines. Information extraction uses natural language processing techniques, such as text analysis and machine learning, to identify and extract information from text-based sources, such as documents, websites, and social media.\n\n### 8. Text Classification\n\nText classification is an NLP technique that enables a computer to categorize text-based sources into predefined categories. This technology is used in many different applications, such as spam filtering, document categorization, and sentiment analysis. Text classification uses natural language processing techniques, such as machine learning and rule-based approaches, to assign a text-based source to a predefined category, such as news, opinion, or advertising.\n\n### 9. Named Entity Recognition\n\nNamed entity recognition (NER) is an NLP technique that enables a computer to identify and classify entities mentioned in human language. This technology is used in many different applications, such as speech recognition, machine translation, and search engines. Named entity recognition uses natural language processing techniques, such as text analysis and machine learning, to identify and categorize entities, such as people, places, organizations, and products, mentioned in text-based sources.\n\n### 10. Text Generation\n\nText generation is an NLP technique that enables a computer to generate human language text. This technology is used in many different applications, such as chatbots, virtual assistants, and email generation. Text generation uses natural language processing techniques, such as machine learning and rule-based approaches, to generate text-based responses to input prompts, such as questions, commands, or requests.\n\n### Conclusion\n\nNatural language processing is a field that has undergone tremendous growth and advancement in recent years, and the applications of NLP are continuing to expand. This article showcased only a few real-world applications, but there are many more, such as automated translation, information extraction, and question answering. The potential uses of NLP are vast and can provide many benefits, from improving customer service to streamlining business processes. With the continued advancement of NLP, we can expect even more exciting and innovative applications in the years to come.\n\n## Recent articles\n\nJun 29, 2023\n\n## 2023â€™s Best Natural Language Processing Courses\n\nAre you looking for the best NLP courses? We have researched and come up with the most popular and best natural language processing courses to sharpen your NLP skills and advance your career.\n\nJun 23, 2023\n\n## The 6 Best NLP Tools to Look Out For in 2023\n\nIn this blog post, we will explore some of the best NLP tools available in 2023. We'll look at six different tools, ranging from open-source software to cloud-based services and even hardware acceleration. These tools are designed to streamline the process of developing and deploying NLP solutions.\n\nJun 22, 2023\n\n## 7 Best Tools for Machine Learning\n\nMachine learning is one of the hottest buzzwords today. As a result, numerous machine learning tools are available. From open-source frameworks like TensorFlow to enterprise-grade platforms like DataBricks, it can be overwhelming to choose the right one. Here are some of the best machine learning tools to look out for.\n\nJun 20, 2023\n\n## The Best Natural Language Processing Project Ideas for Beginners\n\nNLP is an exciting field of study that allows computers to understand and manipulate human language. We'll look at some natural language processing project ideas that are both beginner-friendly and have practical applications.\n\nJun 20, 2023\n\n## Top 7 Data Analysis Tools\n\nThere are a variety of data analysis tools available to help you make sense of the data in your business. This post will explore the best data analysis tools to help you choose the right one for your needs.\n\nJun 16, 2023\n\n## 7 Best Python Data Science Libraries\n\nData science has become an essential part of our daily lives. Python, one of the most popular programming languages, is used by many data scientists. In this post, we will look at the best Python data science libraries.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}