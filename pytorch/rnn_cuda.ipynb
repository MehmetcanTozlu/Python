{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35fdea93-2713-4d0a-b95c-9ffab799185c",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network - RNN (Yinelemeli Sinir Agi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a2e872-b3f4-4eb3-8a58-fa7f5d9a0ab2",
   "metadata": {},
   "source": [
    "## Normalization:\n",
    "CIFAR-10 ve CIFAR-100:\n",
    "Kanal Sayısı: 3 (RGB)\n",
    "Normalizasyon: transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "MNIST:\n",
    "Kanal Sayısı: 1 (Grayscale)\n",
    "Normalizasyon: transforms.Normalize((0.5,), (0.5,))\n",
    "\n",
    "MS-COCO:\n",
    "Kanal Sayısı: 3 (RGB)\n",
    "Normalizasyon: transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "ImageNet:\n",
    "Kanal Sayısı: 3 (RGB)\n",
    "Normalizasyon: Genellikle ImageNet veri seti için kullanılan normalizasyon parametreleri: transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "Fashion-MNIST:\n",
    "Kanal Sayısı: 1 (Grayscale)\n",
    "Normalizasyon: transforms.Normalize((0.5,), (0.5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5095b848-90ea-44d2-99df-7216cca60bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa531407-9ad7-4a65-95ec-2964e6a09603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b229b0b9-2cef-4d63-8f3c-bd6aec0ed8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # her kanalin ort. ve std(stand. sapma) degerini -> 0.5\n",
    "])\n",
    "\"\"\"\n",
    "Normalize icini goruntu kac kanalli ise o kanal sayisi kadar doldurmamiz gerekli.\n",
    "Ornegin, MNIST; gray scale(siyah-beyaz) old. icin sadece Normalize((0.5), (0.5)) yeterli olurken,\n",
    "CIFAR10-CIFAR100; RGB oldugundan Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) olur.\n",
    "R-Read, G-Green, B-Blue\n",
    "transforms.Normalize((mean1, mean2), (std1, std2))\n",
    "transforms.Normalize((mean_R, mean_G, mean_B), (std_R, std_G, std_B))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de745f12-e534-4870-8570-d4190cbd7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNIST(root='', train=True, download=False, transform=transform)\n",
    "test = MNIST(root='', train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d2c46c-6691-4cfd-a859-198e4b3f33e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_data_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5259cbee-3a01-4e8e-be0b-022eb48070d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MNIST.extra_repr of Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: \n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(0.5,))\n",
       "           )>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_loader.dataset.extra_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1429f149-6f73-41d1-9794-cabf8114ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        input_dim: Giriş verisinin boyutu. Örneğin, bir zaman serisi veri setinde her bir zaman adımındaki özellik sayısı.\n",
    "        hidden_dim: Gizli durumun boyutu. RNN'nin içsel gizli durumunun boyutu, yani ağın hatırlama kapasitesini belirler.\n",
    "        layer_dim: RNN'nin kaç katmanlı olduğu. Bir RNN'nin tek bir katmanı, birbirine bağlı bir dizi hücreden oluşur. Eğer bu değer 1 ise, tek bir katmanlı bir RNN olur. Ancak, 2 veya daha fazla bir değerse, bu RNN'nin kaç katmanlı olduğunu belirler. Daha derin (katmanlı) bir yapı, daha karmaşık öğrenme yetenekleri sunabilir, ancak daha fazla hesaplama maliyetiyle birlikte gelir.\n",
    "        output_dim: RNN'nin çıkışının boyutu. Örneğin, sınıflandırma problemlerinde çıkış sınıf sayısı olabilir.\n",
    "        \n",
    "        Giriş boyutu (input_dim): Ağa ne tür bir veri beslediğimizi belirler. Girdi özellik sayısı.\n",
    "        Gizli durum boyutu (hidden_dim): Ağın ne kadar karmaşık bilgileri hatırlayabileceğini belirler. Gizli katmandaki nöron sayısı.\n",
    "        Katman sayısı (layer_dim): Ağın kaç katmanlı olduğunu ve ne kadar karmaşık öğrenme yapabileceğini belirler. RNN katman sayısı.\n",
    "        Çıkış boyutu (output_dim): Ağın ne tür bir çıkış verisi üreteceğini belirler. Çıkış özellik sayısı.\n",
    "        \n",
    "        Katman sayısı (layer_dim) özellikle ilginç bir parametredir çünkü çok katmanlı RNN'ler, daha karmaşık bağlantıları öğrenme yeteneği ile öne çıkabilir. Ancak, bu aynı zamanda eğitim sürecini zorlaştırabilir ve daha fazla hesaplama maliyeti gerektirebilir. Bu parametre, modelin karmaşıklığını ve performansını belirleyen önemli bir kademeli parametredir.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Number of Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim # class'in her yerinden erismek icin boyle yaptik\n",
    "        \n",
    "         # Number of Hidden Layers\n",
    "        self.layer_dim = layer_dim # class'in her yerinden erismek icin boyle yaptik\n",
    "        \n",
    "        # Recurrent Neural Network - RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, bias=True, dropout=0.5,\n",
    "                          nonlinearity='relu', batch_first=True, bidirectional=True)\n",
    "        \"\"\"\n",
    "        input_dim: Giriş verisinin boyutu. Her bir zaman adımındaki özellik sayısını belirtir.\n",
    "        hidden_dim: Gizli durumun boyutu. RNN'nin içsel gizli durumunun boyutunu belirler.\n",
    "        layer_dim: RNN'nin kaç katmanlı olduğu. Eğer bu değer 1 ise, tek katmanlı bir RNN olur. Ancak, 2 veya daha fazla bir değerse, bu RNN'nin kaç katmanlı olduğunu belirler.\n",
    "        nonlinearity: RNN hücresinde kullanılacak aktivasyon fonksiyonunu belirler. Varsayılan değer \"tanh\"tır.\n",
    "        bias: Modelin öğrenme sırasında öğrenilen sapma terimini (bias) kullanıp kullanmayacağını belirler. Varsayılan değer True'dir.\n",
    "        batch_first: Eğer True ise, giriş verisi şekli (batch, time, input_dim) olur; False ise (time, batch, input_dim). Varsayılan değer False'dir. Yani, her bir mini-batch'in başında batch boyutunu belirtmek isteriz.\n",
    "        dropout: Eğitim sırasında kullanılacak dropout katmanının olasılığını belirler. Varsayılan değer 0'dır, yani dropout kullanılmaz.\n",
    "        bidirectional: Eğer True ise, çift yönlü bir RNN oluşturur. Bu, hem ileri hem de geri yönde birbiri ardına iki RNN'yi birleştirir. Varsayılan değer False'dir.\n",
    "        device: Tensorların nerede depolanacağını belirler. Örneğin, torch.device(\"cuda\") veya \"cpu\" olabilir.\n",
    "        dtype: Tensorların veri tipini belirler. Örneğin, torch.float veya torch.double olabilir.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Readout Layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim) # bidirectional verdiğimizde(çift yönlülük) giris ve cikis olacagi icin hidden_dim * 2 yapariz!\n",
    "        \"\"\"\n",
    "        \"Readout Layer\" olarak adlandırılan bu katman, RNN'ın çıktılarını alır ve istediğiniz çıkış boyutuna dönüştürür. Bu katman, genellikle RNN'ın çıktılarından öğrenilen özellikleri temsil eder ve bu özellikleri kullanarak belirli bir görevi gerçekleştirmek üzere eğitilir.\n",
    "        \n",
    "        nn.Linear: Bu, tam bağlantılı (fully connected) bir katman oluşturur. Yani, bu katmanın tüm giriş birimleri (neurons) tüm çıkış birimleriyle bağlıdır.\n",
    "        hidden_dim: Bu, gelen RNN çıktılarının boyutunu temsil eder. RNN katmanından gelen her çıkış, bu boyuta sahip bir vektördür. Giriş özellik sayısı(RNN çıkışının özellik sayısı).\n",
    "        output_dim: Bu, bu tam bağlantılı katmanın çıkış boyutunu temsil eder. Yani, bu katmanın kaç adet çıkış birimine sahip olduğunu belirtir. Çıkış özellik sayısı.\n",
    "        \n",
    "        Bu katmanın temel görevi, RNN tarafından öğrenilen özellikleri, probleminize uygun bir çıkışa dönüştürmektir. Örneğin, bir dil modeli eğitiyorsanız, çıkış boyutu muhtemelen kelime dağarcığınızın boyutuna eşit olacaktır.\n",
    "        \n",
    "        Bu, genellikle bir sınıflandırma problemi için kullanılan bir yapıdır. Eğitim sırasında, RNN'dan gelen çıktılar bu lineer katmana beslenir ve ardından bir softmax aktivasyon fonksiyonu ile geçirilerek olasılık dağılımını elde ederiz. Bu olasılık dağılımı, modele verilen girdi dizisinin hangi sınıfa ait olduğunu belirlemek için kullanılır.\n",
    "        \"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        forward fonksiyonu bir RNN'in bir geçişini tanımlar.\n",
    "        İlk olarak, gizli durumu sıfırlar, ardından her bir zaman adımını çalıştırır ve sadece en son çıkışı kullanarak bir çıkış üretir.\n",
    "        Bu, tipik bir RNN'nin ileri geçişini temsil eder.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim * 2, x.size(0), self.hidden_dim).to(device) # bidirectional(çift yönlülük) verdiğimizde giris ve cikis olacagi icin layer_dim * 2 yapariz!\n",
    "        \"\"\"\n",
    "        İlk olarak, gizli durumu sıfırlarız (h0), bu durumu ilk gizli durum olarak kullanmak üzere tanımlarız.\n",
    "        self.layer_dim kaç tane RNN katmanı kullanılacağını belirtir. Eğer sadece tek bir katman kullanacaksak, bu değer genellikle 1 olacaktır.\n",
    "        x.size(0) gelen veri yığınının boyutu, yani batch size'tır.\n",
    "        self.hidden_dim ise gizli durumun boyutunu ifade eden bir tensör oluşturulur.\n",
    "        \"\"\"\n",
    "        \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \"\"\"\n",
    "        Ardından, self.rnn (nn.RNN katmanı) ile bir zaman adımını çalıştırırız.\n",
    "        out çıkış tensörü, her bir zaman adımındaki çıkışları içerir.\n",
    "        hn ise final gizli durumu içerir.\n",
    "        \"\"\"\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \"\"\"\n",
    "        Son olarak, sadece en son zaman adımının çıkışını kullanarak bir tam bağlantılı katmandan geçiririz.\n",
    "        out[:, -1, :] ifadesi, her bir örneğin en son zaman adımındaki çıkışları alır.\n",
    "        İlk boyut (:): Tüm batch boyutu. Her bir örnek için aynı işlemi yapmak istiyoruz.\n",
    "        İkinci boyut (-1): Son zaman adımını seçer. -1 ifadesi, Python'da sondan bir önceki elemanı ifade eder. Bu durumda, RNN'nin tüm zaman adımları arasından sadece son zaman adımını seçer.\n",
    "        Üçüncü boyut (:): Tüm özellikler. Her bir çıkışın tüm özelliklerini korumak istiyoruz.\n",
    "        \n",
    "        Yani, bu indexing ifadesiyle out[:, -1, :], RNN'nin çıkış tensoründen tüm örneklerin son zaman adımını ve tüm özellikleri alır.\n",
    "        RNN'nin çalışma mantığı göz önüne alındığında:\n",
    "        RNN'nin çıkış tensoru genellikle şu şekildedir: (batch_size, sequence_length, hidden_size)\n",
    "        [:, -1, :] ifadesi bu tensörün tüm batch'lerini, son zaman adımını ve tüm özelliklerini seçer.\n",
    "        \"\"\"\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b5b3259-725c-4968-ac70-6c6e457f03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 128\n",
    "layer_dim = 3\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2340e067-3335-4a9f-8611-c5f5297c9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(input_dim=input_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                layer_dim=layer_dim,\n",
    "                output_dim=output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "296ca5ec-8a7b-46c9-9044-38bcce685d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 5e-4\n",
    "optimizer = RMSprop(model.parameters(), lr=lr, momentum=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81239c78-8773-48f5-9b03-8bff0e03d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 /// Loss: 0.4188695549964905\n",
      "Epoch: 2/30 /// Loss: 0.2226596474647522\n",
      "Epoch: 3/30 /// Loss: 0.06615384668111801\n",
      "Epoch: 4/30 /// Loss: 0.138435959815979\n",
      "Epoch: 5/30 /// Loss: 0.12217563390731812\n",
      "Epoch: 6/30 /// Loss: 0.1830991506576538\n",
      "Epoch: 7/30 /// Loss: 0.14898836612701416\n",
      "Epoch: 8/30 /// Loss: 0.14905282855033875\n",
      "Epoch: 9/30 /// Loss: 0.03261500597000122\n",
      "Epoch: 10/30 /// Loss: 0.05956607684493065\n",
      "Epoch: 11/30 /// Loss: 0.05525694414973259\n",
      "Epoch: 12/30 /// Loss: 0.013808483257889748\n",
      "Epoch: 13/30 /// Loss: 0.09418260306119919\n",
      "Epoch: 14/30 /// Loss: 0.08788786828517914\n",
      "Epoch: 15/30 /// Loss: 0.16557855904102325\n",
      "Epoch: 16/30 /// Loss: 0.07329320162534714\n",
      "Epoch: 17/30 /// Loss: 0.03444778546690941\n",
      "Epoch: 18/30 /// Loss: 0.048056941479444504\n",
      "Epoch: 19/30 /// Loss: 0.005227099638432264\n",
      "Epoch: 20/30 /// Loss: 0.02537042647600174\n",
      "Epoch: 21/30 /// Loss: 0.08549755066633224\n",
      "Epoch: 22/30 /// Loss: 0.013520748354494572\n",
      "Epoch: 23/30 /// Loss: 0.030250828713178635\n",
      "Epoch: 24/30 /// Loss: 0.08969511836767197\n",
      "Epoch: 25/30 /// Loss: 0.06342604756355286\n",
      "Epoch: 26/30 /// Loss: 0.0012414926895871758\n",
      "Epoch: 27/30 /// Loss: 0.025368738919496536\n",
      "Epoch: 28/30 /// Loss: 0.047687627375125885\n",
      "Epoch: 29/30 /// Loss: 0.01571560651063919\n",
      "Epoch: 30/30 /// Loss: 0.059446025639772415\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 30\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for images, labels in train_data_loader:\n",
    "        images, labels = images.view(-1, 28, 28).to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}/{num_epoch} /// Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82e694a4-cb51-4ea5-960e-f4b5e8550478",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a487a884-f076-4247-b7ee-4788b7fb4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for image, label in test_data_loader:\n",
    "        image = image.view(-1, 28, 28).to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        output = model(image)\n",
    "        predicted = torch.max(output.data, 1)[1]\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18bb366c-81c8-4975-8402-b7e3e873546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.68\n"
     ]
    }
   ],
   "source": [
    "accuracy = (correct / total) * 100\n",
    "print('Accuracy: {0}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb3de67-4852-4867-a398-f1d2e0a12bf1",
   "metadata": {},
   "source": [
    "## Tek Image vererek tahmin fonksiyonumuz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7eb3c856-d588-4560-89be-7c16b7319293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSingleImage(model, image):\n",
    "    model.eval()\n",
    "    image = image.view(-1, 28, 28).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad53fd52-fdc6-44e1-acca-725bb0d4673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: 7, Real Class: 7\n"
     ]
    }
   ],
   "source": [
    "sample_image_single, sample_label_single = next(iter(test_data_loader))\n",
    "\n",
    "predicted_single_image = predictSingleImage(model, sample_image_single[0])\n",
    "\n",
    "print(f'Predict: {predicted_single_image}, Real Class: {sample_label_single[0].item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6735b37-0749-4134-8197-d3641ec50f19",
   "metadata": {},
   "source": [
    "## Birden cok Image vererek tahmin fonksiyonumuz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "286274da-255c-491b-8b59-7499103ff6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictImages(model, images):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image in images:\n",
    "            image = image.view(-1, 28, 28).to(device)\n",
    "            output = model(image)\n",
    "            predict = torch.max(output.data, 1)[1]\n",
    "            predictions.append(predict.item())\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2d777b3-391d-4010-b7d5-7aac42caffc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler 1 - Predict 7, Real Class: 7\n",
      "Sampler 2 - Predict 2, Real Class: 2\n",
      "Sampler 3 - Predict 1, Real Class: 1\n",
      "Sampler 4 - Predict 0, Real Class: 0\n",
      "Sampler 5 - Predict 4, Real Class: 4\n",
      "Sampler 6 - Predict 1, Real Class: 1\n",
      "Sampler 7 - Predict 4, Real Class: 4\n",
      "Sampler 8 - Predict 9, Real Class: 9\n",
      "Sampler 9 - Predict 5, Real Class: 5\n",
      "Sampler 10 - Predict 9, Real Class: 9\n"
     ]
    }
   ],
   "source": [
    "sample_images, sample_labels = next(iter(test_data_loader))\n",
    "\n",
    "predicted_images = predictImages(model, sample_images[:10])\n",
    "\n",
    "for i, (predict_class, true_label) in enumerate(zip(predicted_images, sample_labels[:10])):\n",
    "    print(f'Sampler {i+1} - Predict {predict_class}, Real Class: {true_label.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb7545f-25ab-43fe-986b-550159018d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
